{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bexWa5YQuQjx"
      },
      "source": [
        "Student: OUARDIGHI Omar \\\n",
        "Github Repo :\n",
        "\n",
        "\n",
        "Some of the code is adapted from the following tutorial for link prediction: https://docs.dgl.ai/en/0.6.x/tutorials/blitz/4_link_predict.html#sphx-glr-tutorials-blitz-4-link-predict-py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_geometric torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHbB-GrUUWZ-",
        "outputId": "ad0a7770-1352-4eb4-dd16-d96a0d4e1196"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.10/dist-packages (0.3.1+pt21cpu)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt21cpu)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt21cpu)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.10/dist-packages (1.6.3+pt21cpu)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.10/dist-packages (1.2.2+pt21cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install DGL in Colab\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-KFhk6UqZzC",
        "outputId": "1567f25f-9d2d-4689-b37c-2f7c974abe1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-Yb9y5wTuQj3"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import scipy.sparse as sp\n",
        "import dgl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "7zCi0Aa7_4lx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3VHyvdU0uQj7",
        "outputId": "aff7f925-cc6c-4fc5-8e68-00c027efbc18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of edges: 1235\n"
          ]
        }
      ],
      "source": [
        "G_fb = nx.read_edgelist(\"/content/1912.edges\", create_using = nx.Graph(), nodetype = int)\n",
        "num_edges = G_fb.number_of_edges()\n",
        "print(\"Number of edges:\", num_edges)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_features = np.loadtxt(\"/content/1912.feat\", dtype=float)\n",
        "# Iterate over rows and add features to nodes in the graph\n",
        "for node_id, *features in node_features:\n",
        "    node_id = int(node_id)\n",
        "    features = list(map(float, features))\n",
        "\n",
        "    # Check if the node exists in the graph before modifying it\n",
        "    if G_fb.has_node(node_id):\n",
        "        G_fb.nodes[node_id]['features'] = features\n",
        "    else:\n",
        "        print(f\"Node {node_id} does not exist in the graph.\")\n"
      ],
      "metadata": {
        "id": "b1NAIpdupzcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bae6a9-b238-488b-8daf-84f1d1ea9688"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 1933 does not exist in the graph.\n",
            "Node 1949 does not exist in the graph.\n",
            "Node 1956 does not exist in the graph.\n",
            "Node 1961 does not exist in the graph.\n",
            "Node 1969 does not exist in the graph.\n",
            "Node 2008 does not exist in the graph.\n",
            "Node 58 does not exist in the graph.\n",
            "Node 2048 does not exist in the graph.\n",
            "Node 2051 does not exist in the graph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the NetworkX graph to a DGL graph\n",
        "g = dgl.from_networkx(G_fb)\n",
        "node_features_dict = nx.get_node_attributes(G_fb, 'features')\n",
        "\n",
        "# Ensure that node features are aligned with node IDs\n",
        "node_features = [node_features_dict.get(node_id, [0.0]* 480) for node_id in G_fb.nodes()]\n",
        "\n",
        "g.ndata['feat'] = torch.tensor(node_features, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "HzdT-hib7O8A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WHFOPVvuQj_"
      },
      "source": [
        "## Edge Spilitting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.num_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.num_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.num_nodes())\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "\n",
        "neg_eids = np.random.choice(len(neg_u), g.num_edges())\n",
        "test_neg_u, test_neg_v = (\n",
        "    neg_u[neg_eids[:test_size]],\n",
        "    neg_v[neg_eids[:test_size]],\n",
        ")\n",
        "train_neg_u, train_neg_v = (\n",
        "    neg_u[neg_eids[test_size:]],\n",
        "    neg_v[neg_eids[test_size:]],\n",
        ")"
      ],
      "metadata": {
        "id": "nSC6yQWe9f1B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "metadata": {
        "id": "kjIOfhuxt3yC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.num_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.num_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.num_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.num_nodes())"
      ],
      "metadata": {
        "id": "Ny3dQhiN0c4h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "pBy9gagEABwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import SAGEConv\n",
        "import torch.nn as nn\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, \"mean\")\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "ivVB90Jd0Uk4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata[\"score\"][:, 0]"
      ],
      "metadata": {
        "id": "kiuHANUj0rJy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtSYMSFp0-Qg",
        "outputId": "050152b0-8ed7-4553-d695-2b13f20e715e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=147, num_edges=2223,\n",
              "      ndata_schemes={'feat': Scheme(shape=(480,), dtype=torch.float32)}\n",
              "      edata_schemes={})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GraphSAGE(train_g.ndata[\"feat\"].shape[1], 16)\n",
        "\n",
        "pred = DotPredictor()\n",
        "\n",
        "\n",
        "def compute_loss(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score])\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    )\n",
        "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
        "    ).numpy()\n",
        "    return roc_auc_score(labels, scores)"
      ],
      "metadata": {
        "id": "xlt-NCgu01NI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# ----------- 3. set up loss and optimizer -------------- #\n",
        "# in this case, loss will in training loop\n",
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
        ")\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata[\"feat\"])\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print(\"AUC\", compute_auc(pos_score, neg_score))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n4j0BLX-NVY",
        "outputId": "1ff4fe61-a4ac-4c8e-befc-b6f6c7be6f0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 1.0254733562469482\n",
            "In epoch 5, loss: 0.6855635643005371\n",
            "In epoch 10, loss: 0.6629875302314758\n",
            "In epoch 15, loss: 0.6120024919509888\n",
            "In epoch 20, loss: 0.5624158382415771\n",
            "In epoch 25, loss: 0.5396445989608765\n",
            "In epoch 30, loss: 0.5092583298683167\n",
            "In epoch 35, loss: 0.4851110577583313\n",
            "In epoch 40, loss: 0.45005401968955994\n",
            "In epoch 45, loss: 0.4125015139579773\n",
            "In epoch 50, loss: 0.3971270024776459\n",
            "In epoch 55, loss: 0.3890410363674164\n",
            "In epoch 60, loss: 0.37836721539497375\n",
            "In epoch 65, loss: 0.3723665773868561\n",
            "In epoch 70, loss: 0.3676365613937378\n",
            "In epoch 75, loss: 0.36239737272262573\n",
            "In epoch 80, loss: 0.35784998536109924\n",
            "In epoch 85, loss: 0.353302925825119\n",
            "In epoch 90, loss: 0.3487794101238251\n",
            "In epoch 95, loss: 0.34436407685279846\n",
            "AUC 0.9419429920175711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "\n",
        "    # Assuming you have ground truth labels for positive and negative examples\n",
        "    true_labels_pos = torch.ones_like(pos_score)\n",
        "    true_labels_neg = torch.zeros_like(neg_score)\n",
        "\n",
        "    all_true_labels = torch.cat([true_labels_pos, true_labels_neg], dim=0)\n",
        "    all_scores = torch.cat([pos_score, neg_score], dim=0)\n",
        "\n",
        "    # Threshold scores to get binary predictions\n",
        "    predictions = (all_scores >= 0.5).float()\n",
        "\n",
        "    # Calculate accuracy and precision\n",
        "    correct_predictions = (predictions == all_true_labels).float()\n",
        "    accuracy = torch.mean(correct_predictions).item()\n",
        "\n",
        "    true_positive = torch.sum(correct_predictions * (all_true_labels == 1).float()).item()\n",
        "    predicted_positive = torch.sum(predictions).item()\n",
        "\n",
        "\n",
        "\n",
        "    print(\"AUC:\", compute_auc(pos_score, neg_score))\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBA5ugSXKWj3",
        "outputId": "4c5ce0f8-82b7-4175-bc92-8fdaaa912d13"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9419429920175711\n",
            "Accuracy: 0.8825910687446594\n",
            "Precision: 0.8436363636363636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl9XsEbduQkL"
      },
      "source": [
        "## pGNNNet model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the pGNNNet model\n",
        "from pgnn_conv import pGNNConv\n",
        "class pGNNNet(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 num_hid=16,\n",
        "                 mu=0.1,\n",
        "                 p=2,\n",
        "                 K=2,\n",
        "                 dropout=0.5,\n",
        "                 cached=True):\n",
        "        super(pGNNNet, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.lin1 = torch.nn.Linear(in_channels, num_hid)\n",
        "        self.conv1 = pGNNConv(num_hid, 1, mu, p, K, cached=cached)  # Output size is 1 for binary classification\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv1(x, edge_index, edge_weight)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "_AiYNMgkvyWi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "eBl6yvoou417",
        "outputId": "7c6222d4-1935-459e-b66a-1faac0d77c03"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-45109238d9ab>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instantiate the model\n",
        "model = pGNNNet(in_channels=node_feature_matrix.shape[1], num_hid=16, mu=0.1, p=2, K=2, dropout=0.5)\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "# Convert data to PyTorch DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RyVJ6ZBCxUgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pGNNNet(train_g.ndata[\"feat\"].shape[1])\n",
        "\n",
        "pred = DotPredictor()"
      ],
      "metadata": {
        "id": "ATsJGy6A3T4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
        ")\n",
        "\n",
        "# ----------- 4. training -------------------------------- #\n",
        "all_logits = []\n",
        "for e in range(100):\n",
        "    # forward\n",
        "    h = model(train_g, train_g.ndata[\"feat\"].float())\n",
        "    pos_score = pred(train_pos_g, h)\n",
        "    neg_score = pred(train_neg_g, h)\n",
        "    loss = compute_loss(pos_score, neg_score)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if e % 5 == 0:\n",
        "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
        "\n",
        "# ----------- 5. check results ------------------------ #\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    pos_score = pred(test_pos_g, h)\n",
        "    neg_score = pred(test_neg_g, h)\n",
        "    print(\"AUC\", compute_auc(pos_score, neg_score))\n"
      ],
      "metadata": {
        "id": "yrv8aJ7dC99h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNgAjzCsGTY-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "graph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8705649da486b08bea842e9c84ceb153cdc1edfcb92b9e69bcde4d937912465b"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Sl9XsEbduQkL"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}